{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import os\n__print__ = print\ndef print(string):\n    os.system(f'echo \\\"{string}\\\"')\n    __print__(string)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"TEST_PATH = \"../input/nta-landmarks-detection/baseline_NTA/data/test/\" \nTRAIN_PATH = \"../input/nta-landmarks-detection/baseline_NTA/data/train/\"\nSUBMISSION_PATH = \"../input/nta-landmarks-detection/baseline_NTA/data/train/\"\nLANDMARKS = \"../input/nta-landmarks-detection/baseline_NTA/data/train/landmarks.csv\"","execution_count":1,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install imutils","execution_count":2,"outputs":[{"output_type":"stream","text":"Collecting imutils\n  Downloading imutils-0.5.3.tar.gz (17 kB)\nBuilding wheels for collected packages: imutils\n  Building wheel for imutils (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for imutils: filename=imutils-0.5.3-py3-none-any.whl size=25850 sha256=5d1b933a47fb3034745dbc356b7b440132aba1e5fcde0ff12a909ae6715df9a7\n  Stored in directory: /root/.cache/pip/wheels/fc/9c/6d/1826267c72afa51b564c9c6e0f66abc806879338bc593a2270\nSuccessfully built imutils\nInstalling collected packages: imutils\nSuccessfully installed imutils-0.5.3\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"import dlib\nprint(dlib.__version__)","execution_count":3,"outputs":[{"output_type":"stream","text":"19.20.0\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nimport pandas as pd\nimport numpy as np\nimport cv2\nimport gc\nimport time\nimport random\nimport shutil \nfrom tqdm import tqdm\nfrom torch.nn import functional as fnn\nimport torch\nimport torch.nn.functional as F\nimport math\nimport pickle\nimport glob\nfrom PIL import Image\nfrom skimage import io\nimport matplotlib.pyplot as plt\nfrom pyparsing import *\nfrom imutils import face_utils\nimport os.path\nimport csv\nimport re\nfrom zipfile import ZipFile\nfrom os.path import basename\nimport sys\nimport multiprocessing","execution_count":4,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"landmarks_aug = pd.read_csv('../input/ntalandmarks/landmarks_aug_15_30_csv/landmarks_aug_15_30.csv')\nlandmarks_aug.drop('Unnamed: 0', axis = 1, inplace = True)\nos.makedirs('./annotations_train_aug')","execution_count":5,"outputs":[{"output_type":"execute_result","execution_count":5,"data":{"text/plain":"\"landmarks_aug = pd.read_csv('../input/ntalandmarks/landmarks_aug_15_30_csv/landmarks_aug_15_30.csv')\\nlandmarks_aug.drop('Unnamed: 0', axis = 1, inplace = True)\\nos.makedirs('./annotations_train_aug')\""},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Creating txt files with annotations from csv\n#train aug annotations\nfor i in np.arange(landmarks_aug.shape[0]):\n    print(i)\n    s = re.sub('.jpg','',(str(landmarks_aug.iloc[i,0])+'\\n'))\n    print(s)\n    for j in range(0,194*2,2):\n        s+=(str(landmarks_aug.iloc[i,j+1])+' , '+str(landmarks_aug.iloc[i,j+2])+'\\n')\n    with open('/kaggle/working/annotations_train_aug/'+str(i+1)+\".txt\", \"w\") as file:\n        file.write(s)\n        \n#zip all txt annots to zip\n'''with ZipFile('annotations_train_aug_15_30.zip', 'w') as zipObj:\n   # Iterate over all the files in directory\n   for folderName, subfolders, filenames in os.walk('/kaggle/working/annotations_train_aug/'):\n        for filename in filenames:\n            #create complete filepath of file in directory\n            filePath = os.path.join(folderName, filename)\n            # Add file to zip\n            zipObj.write(filePath, basename(filePath))\n        zipObj.close()'''","execution_count":6,"outputs":[{"output_type":"execute_result","execution_count":6,"data":{"text/plain":"\"with ZipFile('annotations_train_aug_15_30.zip', 'w') as zipObj:\\n   # Iterate over all the files in directory\\n   for folderName, subfolders, filenames in os.walk('/kaggle/working/annotations_train_aug/'):\\n        for filename in filenames:\\n            #create complete filepath of file in directory\\n            filePath = os.path.join(folderName, filename)\\n            # Add file to zip\\n            zipObj.write(filePath, basename(filePath))\\n        zipObj.close()\""},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"import multiprocessing\n\noptions = dlib.shape_predictor_training_options()\noptions.cascade_depth = 16\noptions.tree_depth = 5\noptions.num_trees_per_cascade_level = 500\noptions.nu = 0.1\noptions.oversampling_amount = 20\noptions.feature_pool_size = 400\noptions.lambda_param = 0.1\noptions.num_test_splits = 20\noptions.feature_pool_region_padding = 0\n#options.oversampling_translation_jitter=0.01\noptions.be_verbose = True\noptions.num_threads=multiprocessing.cpu_count()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def center_crop(img, new_width=None, new_height=None):        \n\n    width = img.shape[1]\n    height = img.shape[0]\n\n    if new_width is None:\n        new_width = min(width, height)\n\n    if new_height is None:\n        new_height = min(width, height)\n\n    left = int(np.ceil((width - new_width)/2))\n    right = int(np.floor((width + new_width)/2))\n\n    top = int(np.ceil((height - new_height)/2))\n    bottom = int(np.floor((height + new_height)/2))\n\n    return int(left),int(top),int(right),int(bottom)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"HELEN_IMGS_ABS_FILEPATH = '/kaggle/input/ntalandmarks/train_pngs_15_30/train_pngs/'\n#HELEN_ANNOTATIONS_ABS_FILEPATH_TRAIN_ALL = '/kaggle/input/ntalandmarks/annotations_train_aug_15_30/'\nHELEN_ANNOTATIONS_ABS_FILEPATH_TRAIN_ALL = '/kaggle/working/annotations_train_aug/'\nface_cascade = cv2.CascadeClassifier('/kaggle/input/ntalandmarks/haarcascade/haarcascade_frontalface_default.xml')\nhelen_annotations_filelist_train_all = glob.glob(HELEN_ANNOTATIONS_ABS_FILEPATH_TRAIN_ALL+'*.txt')\n\nxml_template_header = \"\"\"<?xml version='1.0' encoding='ISO-8859-1'?>\n<?xml-stylesheet type='text/xsl' href='image_metadata_stylesheet.xsl'?>\n<dataset>\n<name>train dataset</name>\n<comment>Created by annakuchko</comment>\n<images>\\n\"\"\"\n\nxml_template_footer = \"\"\"</images>\n</dataset>\"\"\"\n\ndef generate_xml(annots_path):\n    xml = xml_template_header\n\n    c = 0\n    for file_name in annots_path:\n        with open(file_name, 'r') as file:\n            \n            img_filename = HELEN_IMGS_ABS_FILEPATH + file.readline().replace('\\n', '') + \\\n                '.png'  \n            print(img_filename)\n\n            image_xml = f\"\"\"  <image file='{img_filename}'>\"\"\"\n\n            gray_image = cv2.imread(img_filename, cv2.IMREAD_GRAYSCALE)\n\n            x, y, w, h = [int for i in range(4)]\n\n            if len(face_position(gray_image)) == 0:\n                print(\n                    f\"No faces detected: {img_filename}\")\n                x,y,w,h = center_crop(gray_image)\n            else:\n                x, y, w, h = face_position(gray_image)[0]\n            w = x+w\n            h = y+h\n\n            image_xml += f\"\\n\\t<box top = '{int(float(y))}' left = '{int(float(x))}' width = '{int(float(w))}' height = '{int(float(h))}'>\\n\"\n\n            i = 0\n            for line in file:\n                x, y = line.replace('\\n', '').replace(\n                    '\\r', '').replace(' ', '').split(',')\n                image_xml += f\"\\t  <part name='{str(i).zfill(3)}' x='{int(float(x))}' y='{int(float(y))}'/>\\n\"\n                i += 1\n            image_xml += '\\t</box>\\n'\n            image_xml += '  </image>\\n'\n            print(c)\n            c+=1\n\n            xml += image_xml\n\n    xml += xml_template_footer\n    return xml\n\ndef face_position(gray_img):\n    faces = face_cascade.detectMultiScale(gray_img,\n                                          scaleFactor=1.0005,\n                                          minNeighbors=3,\n                                          minSize=(\n                                              int(len(gray_img[0]) / 2.5),\n                                              int(len(gray_img) / 2.5))\n                                         )\n    return faces","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#generating xml\nwith open('annot_train_all_aug_15_30_xml.xml', 'w') as out_xml_file:\n    xml = generate_xml(helen_annotations_filelist_train_all)\n    out_xml_file.write(xml)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#train_all_xml_filename = '/kaggle/input/ntalandmarks/annot_train_all_aug_15_30_xml.xml'\ntrain_all_xml_filename = '/kaggle/working/annot_train_all_aug_15_30_xml.xml'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#training dlib shape predictor ~2 hours\nprint(\"Start training\")\ndlib.train_shape_predictor(train_all_xml_filename, \"train_all_15_30.dat\", options)\nprint(\"Finish\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def measure_model_error(model, xml_annotations):\n    error = dlib.test_shape_predictor(xml_annotations, model)\n    print(\"Error of the model: {} is {}\".format(model, error))\n    \nmeasure_model_error('/kaggle/working/train_all_15_30.dat', train_all_xml_filename)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lbls = pd.read_csv('/kaggle/input/nta-landmarks-detection/baseline_NTA/data/test/test_points.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub = pd.DataFrame(np.zeros((330,194*2+1)))\npredictor = dlib.shape_predictor(\"/kaggle/working/train_all_15_30.dat\")\ndetector = dlib.get_frontal_face_detector()\nff_detector = dlib.get_frontal_face_detector()\n\nsub_list = []\nnames_list = []\nsubzeroes = pd.read_csv('/kaggle/input/nta-landmarks-detection/SubmitAllZero.csv')\nfaces_folder = '/kaggle/input/ntalandmarks/test_pngs/test_pngs/'\nprint(\"Showing detections and predictions on the images in the faces folder...\")\n\n\nfor i, f in enumerate(lbls['filename']):\n    print(i)\n    print(\"Processing file: {}\".format(f))\n    img = cv2.imread(faces_folder+f[:-4]+'.png', cv2.IMREAD_GRAYSCALE)\n    dets = face_position(img)\n    if len(dets)==0:\n        ff_dets = ff_detector(img,1)\n        if len(ff_dets)!=0:\n            shape = predictor(img, ff_dets[0])\n            shape = face_utils.shape_to_np(shape)\n            print('Faces detected by ff detector')\n        else:\n            left, top, right, bottom = center_crop(img)\n            dets = dlib.rectangle(int(left), int(top), int(left+right), int(top+bottom))\n            shape = predictor(img, dets)\n            shape = face_utils.shape_to_np(shape)\n            print('No faces detected by cascade and frontal_face detector, use the whole img')\n\n    else:\n        x,y,w,h = dets[0]\n        dets = dlib.rectangle(int(x), int(y), int(w+x), int(h+y))\n        shape = predictor(img, dets)\n        shape = face_utils.shape_to_np(shape)\n        print('Faces detected by cascade detector')\n    sub.iloc[i,0] = f[:-4]+'.jpg'\n    sub.iloc[i,1:] = shape.ravel()\n    sub_list.append(shape)\n    names_list.append(f)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"landmarks = pd.read_csv('../input/nta-landmarks-detection/baseline_NTA/data/train/landmarks.csv')\nsub.columns = landmarks.columns\n\ndf = pd.read_csv('../input/nta-landmarks-detection/baseline_NTA/data/test/test_points.csv')\nfor i in np.arange(330):\n    c = [int(s) for s in df.iloc[i,1][1:-1].split(',')] \n    print(i)\n    d = np.array(sub_list[i])\n    subzeroes.iloc[i,1:] = d[c].ravel()\nsubzeroes.to_csv('submission.csv', index = False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}